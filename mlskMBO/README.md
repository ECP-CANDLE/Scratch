Model Based Optimization using Python and scikit-learn machine learning instead of R. 

Short term goal: replace Random Forest Regression with Gaussian Process Regression as the model, even when there are categorical predictors. 

Long term: functional equivalence to mlrMBO.
ParameterSet object modelled on R version, sampling, Lower Confidence Bound, and focus are implemented.

Creates Python dictionaries for NT3 and optionally runs them in Keras.

Any predictor in scikit-learn for which standard errors are available should be fair game.


Focus Algorithm is an object-oriented Python adaptation of Algorithm 1 from the mlrMBO paper:

    Algorithm 1 Infill Optimization: Focus Search.
    Require: infill criterion c : X → R, control parameters nrestart, niters, npoints
    for u∈{1,...,nrestart} do 
        Set X ̃ = X
        for v ∈ {1,...,niters} do
            generate random design D ⊂ X ̃ of size npoints
            compute x∗u,v = (x∗1 , ..., x∗d ) = arg minx∈D c(x)
            shrink X ̃ by focusing on x∗:
            for each search space dimension X ̃ in X ̃ do
                if X ̃ numeric: X ̃ = [li, ui] then
                    li=max{li,x∗i − (ui−li)/4}
                    ui=min{ui,x∗i + (ui−li)/4}
                end if
                if X ̃ categorical: X ̃ = {vi1 ,...,vis }, s > 2 then
                    x ̄ = sample one category uniformly from X ̃ \x∗
                    X ̃i = X ̃i \ x ̄i
                end if 
            end for
        end for
    end for
    Return x∗ = argmin c(x∗u,v) u∈{1,...,nrestart },v∈{1,...,niters }


[mlrMBO: A Modular Framework for Model-Based Optimization of Expensive Black-Box Functions
Bernd Bischla, Jakob Richterb, Jakob Bossekc, Daniel Hornb, Janek Thomasa, Michel Langb]


mlskMBO.py currently is configured to gives a minimalistic demonstration.

Initially, a parameter grid is enumerated, the parameters are evaluated in keras by running nt3_baseline_keras2, and the results are saved into json log files.  The code in nt3_run_data scrapes the json logs, and collects the results into a pandas dataframe.   

To streamline demonstration, results from an initial grid with a few hundred points are stored in nt3_initial_data.csv and read into a dataframe.  The get_nt3_data function can be directed to the location of json logs from NT3 if available.

A Gaussian Process Regression models the response (validation loss), and scikit-learn 'optimize' finds the location of the parameter values which give the minimal value of the model.  This is used as the starting point for the focus algorithm, which draws parameter values at random, but becoming closer to the starting point.  The resulting list of dictionaries may optionally be evaluated by nt3_baseline_keras2.

The json log files which are produced may then be read in with get_nt3_data, the GPR model updated, and new candidate parameters proposed... 

Graphs of the validation loss show that the smallest loss found when using initial data with parameters generated by grid search was over 0.2.  (In the portion of the grid discussed below, the best value was over 0.54)  In comparison, using the recommendations from GPR to generate a small sample with the focus algorithm, out of only 28 points evaluated, half a dozen had markedly better loss values, including 3 values around 0.07.

![initial data](https://github.com/ECP-CANDLE/Scratch/blob/master/mlskMBO/validation_loss_initial_grid.png) 
![recommendations from GPR](https://github.com/ECP-CANDLE/Scratch/blob/master/mlskMBO/validation_loss_GPR_recommendations.png)

Initial parameter combinations were obtained by systematically enumerating over a grid, and the validation loss evaluated in keras:

![validation_loss](https://github.com/ECP-CANDLE/Scratch/blob/master/mlskMBO/validation_loss.png)

The Gaussian Process Regression predictions exhibit periodicity at different scales when plotted sequentially because of the orderly variation of the parameters as the grid was enumerated.

![gpr_predictions](https://github.com/ECP-CANDLE/Scratch/blob/master/mlskMBO/GPR_predictions.png)

Although the scale of the fluctuations in the predicted values is much more subdued than the variation in the loss values, the dips in the predicted values correlate well with the promiment downward spikes in the observed loss.  A comparable analysis using scikit-learn's Random Forest Regression as the predictor (as mlrMBO would do) showed no skill in identifying the spikes.

![validation_loss_gpr_predictions](https://github.com/ECP-CANDLE/Scratch/blob/master/mlskMBO/validation_loss_GPR_predictions.png)

In the underlying multivariate space (not the linear ordering from the grid enumeration), scikit-learn's optimize has no difficulty finding the global minimum.  As noted above, proposing that point plus 27 nearby candidates using the focus algorithm adapted from mlrMBO found half a dozen which were dramatically improved over the training data.
